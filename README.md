# NarrativetoNumbers

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/framework-FastAPI-green)](https://fastapi.tiangolo.com/)
[![Code style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **Source code and experimental materials for:**
> 
> *From Narrative to Numbers: Evaluating Survey Questionnaires with Large Language Models*
> 
> This research investigates how Large Language Models can convert free-text workload narratives into quantitative NASA-TLX dimension scores, bridging qualitative and quantitative assessment methodologies in human-computer interaction research.

---

## ğŸ“– Overview

**Narrative to Numbers** is a web-based research platform that implements a dual-interface NASA-TLX assessment system:

1. **Sliding Puzzle Task** â€“ A controlled cognitive load induction tool (HTML5 Canvas) with two difficulty levels:
   - **Easy**: Manhattan Distance 8â€“16, minimum 20s completion
   - **Hard**: Manhattan Distance 56â€“76, minimum 30s completion

2. **Multimodal NASA-TLX Assessment** â€“ Participants rate workload using:
   - **Slider ratings** (1â€“7 Likert scale)
   - **Free-text descriptions** (qualitative narratives)
   - Counterbalanced order across conditions

3. **LLM-Powered Analysis Pipeline** â€“ Automated processing of descriptive responses:
   - **Validator**: Checks coherence, topic relevance, and quality using LLM (with offline fallback)
   - **Rater**: Converts validated text to NASA-TLX scores (1â€“7) per dimension
   - **Exports**: Structured CSV outputs for statistical analysis (ICC, TOST, Pearson correlations)

---

## ğŸ¯ Key Features

| Feature | Description |
|---------|-------------|
| **Counterbalanced Design** | Tracks Sequence A vs. B assignments to minimize order effects |
| **Session Management** | HTTPOnly cookies for secure, privacy-respecting participant tracking |
| **Real-time Data Export** | Automatic CSV generation to multiple formats |
| **Pilot vs. Research Modes** | Separate data directories for pilot testing and formal study |
| **Transparent Provenance** | Every response logged with LLM source (online/offline), validation quality, and timestamp |

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- **Python 3.9+** (3.10+ recommended)
- **OpenAI API Key** (optional, for LLM validation and scoring)
- **SQLite 3** (built-in with Python)

### Step 1: Clone the Repository
```bash
git clone https://github.com/Akashdeep1000/NarrativetoNumbers.git
cd NarrativetoNumbers
```

### Step 2: Create and Activate Virtual Environment
```bash
# Using Python venv
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# OR using Conda (recommended for research projects)
conda create -n narrative2numbers python=3.9
conda activate narrative2numbers
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment Variables
Create a `.env` file in the root directory:

```env
# LLM Configuration
OPENAI_API_KEY=sk-your-api-key-here
LLM_MODEL=gpt-4o-mini

```

---

## ğŸš€ Running the Application

### Start the Development Server
```bash
uvicorn app.main:app --reload --port 8088
```

Then open your browser to: **http://127.0.0.1:8088**

---

## ğŸ“‚ Project Structure

```
NarrativetoNumbers/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # FastAPI routes & core logic (15 KB)
â”‚   â”‚                                 # - Session management, puzzle task, data collection
â”‚   â”œâ”€â”€ db.py                        # SQLAlchemy ORM setup
â”‚   â”œâ”€â”€ models.py                    # Database models
â”‚   â”‚                                 # - Participant, Session, Demographics, Level
â”‚   â”œâ”€â”€ schemas.py                   # Pydantic request/response schemas
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_tlx.py               # LLM validation & scoring pipeline
â”‚       â”‚                             # - validate_descriptive(): Check quality & coherence
â”‚       â”‚                             # - rate_descriptive(): Generate 1â€“7 scores per dimension
â”‚       â”‚                             # - Includes offline heuristic fallback
â”‚       â”œâ”€â”€ exporter.py              # Multi-format CSV export logic
â”‚       â”‚                             # - Per-participant folders
â”‚       â”‚                             # - Aggregated exports for analysis
â”‚       â””â”€â”€ latin_square.py          # Counterbalancing utility (optional, for 4-level designs)
â”‚
â”œâ”€â”€ templates/                        # Jinja2 HTML templates
â”‚   â”œâ”€â”€ base.html                    # Base layout & CSS injection point
â”‚   â”œâ”€â”€ index.html                   # Consent & home page
â”‚   â”œâ”€â”€ demographics.html            # Age, gender, puzzle experience form
â”‚   â”œâ”€â”€ study.html                   # Puzzle task + NASA-TLX survey interface
â”‚   â”œâ”€â”€ post.html                    # Post-study questionnaire (optional)
â”‚   â””â”€â”€ thankyou.html                # Completion & gratitude screen
â”‚
â”œâ”€â”€ static/
â”‚   â”‚
â”‚   â””â”€â”€ js/                          # Frontend logic (puzzle game, AJAX)
â”‚       â”œâ”€â”€ game.js                  # 17.7 KB - Puzzle implementation
â”‚       â”‚                             # - Puzzle class (4x4 sliding puzzle with canvas rendering)
â”‚       â”‚                             # - Timer class (min:sec display with performance.now())
â”‚       â”‚                             # - shuffleToRange() (difficulty control via Manhattan distance)
â”‚       â”‚                             # - initStudy() (orchestrates game + NASA-TLX flow)
â”‚       â”‚
â”‚       â””â”€â”€ main.js                  # 2.3 KB - Form handling & API utilities
â”‚                                     # - Demographics form submission via POST /api/demographics
â”‚                                     # - postJson() (fetch wrapper with error parsing)
â”‚                                     # - Error message display
â”‚
â”œâ”€â”€ data/                            # Data storage (auto-generated)
â”‚   â”œâ”€â”€ by_participant/              # Folder per participant (P001_name/, P002_name/, etc.)
â”‚   â”‚   â”œâ”€â”€ {participant_id}/
â”‚   â”‚   â”‚   â”œâ”€â”€ info.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ demographics.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ levels.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ tlx_slider.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ tlx_descriptive_wide.csv
â”‚   â”‚   â”‚   â””â”€â”€ tlx_descriptive_long.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ exports/                     # Full snapshots (by timestamp)
â”‚   â”‚   â”œâ”€â”€ 20250101_120000/
â”‚   â”‚   â”‚   â”œâ”€â”€ participants.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ demographics.csv
â”‚   â”‚   â”‚   â””â”€â”€ levels.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ meta/
â”‚   â”‚   â”œâ”€â”€ pno_counter.txt          # Participant number counter
â”‚   â”‚   â””â”€â”€ sequence_counts.json     # Seq A/B balance tracking
â”‚   â”‚
â”‚   â””â”€â”€ responses.db                 # SQLite database
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Environment variables (NOT in git)
â”œâ”€â”€ .gitignore                       # Ignore __pycache__, .env, data/
â”œâ”€â”€ LICENSE                          # MIT License
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”‘ Core Endpoints

### Authentication & Consent
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `GET /` | GET | Home page (consent form) |
| `POST /api/consent` | POST | Process consent & create session |

### Study Interface
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `GET /demographics` | GET | Demographic form page |
| `POST /api/demographics` | POST | Submit demographics |
| `GET /study` | GET | Puzzle task + NASA-TLX page |
| `POST /api/session/start` | POST | Initialize puzzle session |
| `POST /api/level/start` | POST | Start a specific level |
| `POST /api/level/complete` | POST | Submit puzzle completion + moves/time |
| `POST /api/tlx/slider` | POST | Record slider-based NASA-TLX ratings |
| `POST /api/tlx/descriptive` | POST | Submit free-text + get LLM validation & scores |


---

## ğŸ§© Puzzle Implementation Details

### Difficulty Calibration
Puzzles are generated to match specific Manhattan distance (MD) ranges:
- **Easy (MD 8â€“16)**: 20 minimum seconds required by server
- **Hard (MD 56â€“76)**: 30 minimum seconds required by server


---

### Configuration

In `app/services/llm_tlx.py`:
```python
MIN_WORDS = 8              # Minimum text length
LLM_MODEL = "gpt-4o-mini"  # Set via env: LLM_MODEL=gpt-4o-mini
```

---

## ğŸ” Privacy & Security

### Data Protection
- **HTTPOnly Cookies**: Session tokens cannot be accessed via JavaScript
- **No plaintext passwords**: Not applicable (consent-based study)
- **Participant anonymization**: Use participant_no instead of email in exports

### Data Retention
- Raw data stored locally in `./data/` directory
- Export snapshots archived with timestamp

### IRB Compliance
- Consent recorded in database (`participants.consent` flag)
- Demographic data minimal (age band, gender, puzzle experience)
- Free-text responses logged separately from PII


---


## ğŸ“œ License

This project is distributed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---
